{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCpzw8-Mtx6l",
        "outputId": "01d61ced-669f-48d8-e388-aa66f5dba4a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLWgrnbmucg2",
        "outputId": "6ad8ed81-95c5-46f2-c930-03b6c78dd40e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.5.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.26.4)\n",
            "Downloading trimesh-4.5.3-py3-none-any.whl (704 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/704.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "b4EXnVWp2qdY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gef0EBUltvme"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import trimesh\n",
        "import scipy.io\n",
        "from torchvision.datasets import ImageFolder\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/pix3d/byop-2425/models')\n",
        "from gan2 import CompactGenerator, CompactDiscriminator\n",
        "# import sys\n",
        "# sys.path.append(\"../models\")\n",
        "# from gan import Discriminator, Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma5qIYpRtvmg"
      },
      "outputs": [],
      "source": [
        "mesh = trimesh.load('../../model/bed/IKEA_BEDDINGE/model.obj')\n",
        "mesh_v = list(mesh.geometry.values())[0]\n",
        "vertices = np.array(mesh_v.vertices)\n",
        "faces = np.array(mesh_v.faces)\n",
        "print(vertices)\n",
        "print(faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xD-KHL_Xtvmg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m5mrhAjTtvmh"
      },
      "outputs": [],
      "source": [
        "json_dir = \"/content/drive/MyDrive/pix3d/pix3d.json\"\n",
        "with open(json_dir, 'r') as f:\n",
        "    data = json.load(f)\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = pd.read_csv(\"/content/sample_data.csv\")"
      ],
      "metadata": {
        "id": "eKhYq6VYE1zi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t3KFmUmvtvmh"
      },
      "outputs": [],
      "source": [
        "class pix3d_dataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None, data_dir='/content/drive/MyDrive/pix3d/'):\n",
        "        self.transform = transform\n",
        "        self.dataframe = dataframe\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data_dir + self.dataframe.iloc[idx]['img']\n",
        "        mask_path = self.data_dir + self.dataframe.iloc[idx]['mask']\n",
        "        voxel_path = self.data_dir + self.dataframe.iloc[idx]['voxel']\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L')\n",
        "        voxel = scipy.io.loadmat(voxel_path)['voxel']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        voxel = torch.tensor(voxel, dtype=torch.float32).unsqueeze(0)\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'mask': mask,\n",
        "            'voxel': voxel\n",
        "        }\n",
        "        return sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P9aEqnJ5tvmh"
      },
      "outputs": [],
      "source": [
        "# latent_dim = 50\n",
        "# hidden_dim = 32\n",
        "lr = 0.0002\n",
        "batch_size = 1\n",
        "num_epochs = 5\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "dataset = pix3d_dataset(sample_df, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "# generator = SmallGenerator(img_dim=3, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
        "# discriminator = SmallDiscriminator(voxel_dim=1, img_dim=3, hidden_dim=hidden_dim).to(device)\n",
        "\n",
        "# optimizer_g = optim.SGD(generator.parameters(), lr=lr, momentum = 0.9)\n",
        "# optimizer_d = optim.SGD(discriminator.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "# criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0Eo-Hhhtvmh",
        "outputId": "41da45d1-8df9-42ac-b2a8-78c252b0aed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 3, 128, 128])\n",
            "Voxel shape: torch.Size([1, 1, 128, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(dataloader):\n",
        "    real_images = data['image'].to(device)\n",
        "    real_voxels = data['voxel'].to(device)\n",
        "    print(\"Image shape:\", real_images.shape)\n",
        "    print(\"Voxel shape:\", real_voxels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm as tqdm"
      ],
      "metadata": {
        "id": "4kRi_rpcv1xS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_gan(generator, discriminator, dataloader, device, num_epochs=5, lr=0.0002, latent_dim=50):\n",
        "    optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        for i, data in enumerate(dataloader):\n",
        "            real_images = data['image'].to(device)\n",
        "            real_voxels = data['voxel'].to(device)\n",
        "\n",
        "            batch_size = real_images.size(0)\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "            #real data\n",
        "            outputs = discriminator(real_voxels, real_images)\n",
        "            d_loss_real = criterion(outputs, real_labels)\n",
        "\n",
        "            #fake data\n",
        "            z = torch.randn(batch_size, latent_dim).to(device)\n",
        "            fake_voxels = generator(real_images, z)\n",
        "\n",
        "            outputs = discriminator(fake_voxels.detach(), real_images)\n",
        "            d_loss_fake = criterion(outputs, fake_labels)\n",
        "\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            optimizer_g.zero_grad()\n",
        "\n",
        "            fake_voxels = generator(real_images, z)\n",
        "            outputs = discriminator(fake_voxels, real_images)\n",
        "            g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
        "\n",
        "        torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')\n",
        "        torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')\n",
        "\n",
        "# Usage\n",
        "generator = CompactGenerator(img_dim=3, hidden_dim=16, latent_dim=50).to(device)\n",
        "discriminator = CompactDiscriminator(voxel_dim=1, img_dim=3, hidden_dim=16).to(device)\n",
        "train_gan(generator, discriminator, dataloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fydWcOM67-gg",
        "outputId": "c7937622-16b9-44c5-dcd9-71de0f3bd708"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/100], D Loss: 1.3964293003082275, G Loss: 0.7098605036735535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [07:32<30:08, 452.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Step [100/100], D Loss: 1.3865364789962769, G Loss: 0.6872125864028931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [13:17<19:28, 389.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Step [100/100], D Loss: 1.4212024211883545, G Loss: 0.6563372015953064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [19:04<12:20, 370.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Step [100/100], D Loss: 1.428591012954712, G Loss: 0.6658902764320374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:53<06:01, 361.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Step [100/100], D Loss: 1.3729350566864014, G Loss: 0.6639695763587952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:37<00:00, 367.59s/it]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}